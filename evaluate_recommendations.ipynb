{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "plt.rcParams[\"text.usetex\"] =True"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-30T22:05:40.916086600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "## Helper Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the jaccard distance to measure how the recommendation lists change\n",
    "def jaccard_distance(x, y):\n",
    "    return 1 - len(set(x).intersection(y)) / len(set(x).union(y))\n",
    "\n",
    "# average the results of our evaluation metrics over all seeds\n",
    "def average_results(results):\n",
    "    return np.mean([np.mean([results_f[uid] for uid in results_f]) for idx, results_f in enumerate(results)])\n",
    "\n",
    "# by sorting the recommendation files (.pkl), we can ensure that all methods process the files in the same order\n",
    "def sort_files(path):\n",
    "    base, dataset_name, model_name, eps = path.split(sep=\"/\")\n",
    "    files = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".pkl\"):\n",
    "            files.append(file)\n",
    "\n",
    "    LEN_PREFIX = len(model_name) + 1\n",
    "    LEN_SUFFIX = len(\".pkl\")\n",
    "    timestamps = [filename[LEN_PREFIX:-LEN_SUFFIX] for filename in files]\n",
    "    sorted_timestamps = sorted(timestamps)\n",
    "    sorted_files = [model_name + \"-\" + timestamp + \".pkl\" for timestamp in sorted_timestamps]\n",
    "\n",
    "    return sorted_files\n",
    "\n",
    "# compute the evaluation metrics, i.e., recall, arp, and popularity lift\n",
    "def _compute_metrics(recommendation_list, item_popularity, groundtruth, user_profile_popularity, impacted_users=None):\n",
    "    recall, arp, upp = dict(), dict(), dict()\n",
    "    poplift = []\n",
    "    for uid, recs in recommendation_list.items():\n",
    "        if impacted_users is not None:\n",
    "            if uid not in impacted_users:\n",
    "                continue\n",
    "\n",
    "        recall[uid] = len(groundtruth.loc[uid].intersection([str(iid) for iid in recs])) / len(groundtruth.loc[uid])\n",
    "        arp[uid] = np.mean([item_popularity.loc[str(item_id)] for item_id in recs])\n",
    "        upp[uid] = user_profile_popularity.loc[uid]\n",
    "\n",
    "    # poplift is based on user groups, not single users\n",
    "    poplift.append((np.mean(list(arp.values())) - np.mean(list(upp.values()))) / np.mean(list(upp.values())))\n",
    "    return recall, arp, np.mean(poplift)\n",
    "\n",
    "\n",
    "# compute evaluation metrics across different seeds/files\n",
    "def _analyze_recommendations(dirpath, item_popularity, groundtruth, user_profile_popularity, impacted_users=None):\n",
    "    files = sort_files(dirpath)\n",
    "    recalls, arps, poplifts = [], [], []\n",
    "    for idx, file in enumerate(files):\n",
    "        with open(dirpath + \"/\" + file, \"rb\") as f:\n",
    "            recommendation_list = pl.load(f)\n",
    "        if impacted_users is not None:\n",
    "            recall, arp, poplift = _compute_metrics(recommendation_list, item_popularity, groundtruth, user_profile_popularity, impacted_users=impacted_users[idx])\n",
    "        else:\n",
    "            recall, arp, poplift = _compute_metrics(recommendation_list, item_popularity, groundtruth, user_profile_popularity)\n",
    "\n",
    "        recalls.append(recall)\n",
    "        arps.append(arp)\n",
    "        poplifts.append(poplift)\n",
    "\n",
    "    return recalls, arps, poplifts\n",
    "\n",
    "# obtain the set of impacted user (per seed/file)\n",
    "def _get_impacted_users(dirpath_nodp, dirpath_dp):\n",
    "    files_nodp = sort_files(dirpath_nodp)\n",
    "    files_dp = sort_files(dirpath_dp)\n",
    "\n",
    "    impacted_users, frac_impacted_users, avg_dist = [], [], []\n",
    "    for file_nodp, file_dp in zip(files_nodp, files_dp):\n",
    "        with open(dirpath_nodp + \"/\" + file_nodp, \"rb\") as f:\n",
    "            recommendation_list_nodp = pl.load(f)\n",
    "\n",
    "        with open(dirpath_dp + \"/\" + file_dp, \"rb\") as f:\n",
    "            recommendation_list_dp = pl.load(f)\n",
    "\n",
    "        impacted_users_f, dist_f = [], []\n",
    "        for uid, recs_dp in recommendation_list_dp.items():\n",
    "            recs_nodp = recommendation_list_nodp[uid]\n",
    "\n",
    "            dist = jaccard_distance(recs_nodp, recs_dp)\n",
    "            if dist > 0:\n",
    "                impacted_users_f.append(uid)\n",
    "                dist_f.append(dist)\n",
    "\n",
    "        frac_impacted_users.append(len(impacted_users_f) / len(recommendation_list_dp))\n",
    "        impacted_users.append(impacted_users_f)\n",
    "        dist_f = dist_f if len(dist_f) > 0 else 0\n",
    "        avg_dist.append(np.mean(np.nanmean(dist_f)))\n",
    "    return impacted_users, np.mean(frac_impacted_users), np.mean(avg_dist)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate metrics for different seeds and epsilons"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the main evaluation method, calculates all evaluation metrics for all seeds/files and epsilon values\n",
    "def analyze(dataset_name, model_name, groundtruth, user_profile_popularity, item_popularity):\n",
    "    dir = \"saved/\" + dataset_name + \"/\" + model_name + \"/\"\n",
    "    results_nodp = _analyze_recommendations(dirpath=dir + \"nodp\", item_popularity=item_popularity, user_profile_popularity=user_profile_popularity, groundtruth=groundtruth)\n",
    "    recall_nodp, arp_nodp, poplift_nodp = results_nodp\n",
    "\n",
    "    print(\"No DP: %.4f (recall), %.4f (arp), %.4f (poplift)\" % (average_results(recall_nodp), average_results(arp_nodp), np.mean(poplift_nodp)))\n",
    "\n",
    "    delta_recall, delta_arp, delta_poplift = [], [], []\n",
    "    percentage_impacted_users, average_jaccard_distance = [], []\n",
    "    for eps in [0.01, 0.1, 1, 2, 3, 4, 5][::-1]:\n",
    "        users, frac_impacted, jacc = _get_impacted_users(dirpath_nodp=dir + \"nodp\", dirpath_dp=dir + \"e\" + str(eps))\n",
    "\n",
    "        results_eps = _analyze_recommendations(dirpath=dir + \"e\" + str(eps), item_popularity=item_popularity, groundtruth=groundtruth, user_profile_popularity=user_profile_popularity, impacted_users=users)\n",
    "        recall_eps, arp_eps, poplift_eps = results_eps\n",
    "\n",
    "        # delta metrics are calculated per seed/file and averaged afterwards\n",
    "        delta_recall_eps, delta_arp_eps, delta_poplift_eps = [], [], []\n",
    "        for file_idx in range(len(users)):\n",
    "            delta_recall_eps_f, delta_arp_eps_f, delta_poplift_eps_f = [], [], []\n",
    "            for uid in recall_eps[file_idx].keys():\n",
    "                delta_recall_eps_f.append((recall_eps[file_idx][uid] - recall_nodp[file_idx][uid]) / recall_nodp[file_idx][uid] if recall_nodp[file_idx][uid] != 0 else np.nan)\n",
    "                delta_arp_eps_f.append((arp_eps[file_idx][uid] - arp_nodp[file_idx][uid]) / arp_nodp[file_idx][uid] if arp_nodp[file_idx][uid] != 0 else np.nan)\n",
    "            delta_recall_eps.append(100 * np.nanmean(delta_recall_eps_f))\n",
    "            delta_arp_eps.append(100 * np.nanmean(delta_arp_eps_f))\n",
    "            delta_poplift_eps.append(100 * (poplift_eps[file_idx] - poplift_nodp[file_idx]) / poplift_nodp[file_idx])\n",
    "\n",
    "        delta_recall.append(np.mean(delta_recall_eps))\n",
    "        delta_arp.append(np.mean(delta_arp_eps))\n",
    "        delta_poplift.append(np.mean(delta_poplift_eps))\n",
    "\n",
    "        percentage_impacted_users.append(100 * frac_impacted)\n",
    "        average_jaccard_distance.append(jacc)\n",
    "\n",
    "        print(\"eps: %f -> %f%% (recall), %f%% (arp), %f%% (poplift), %f (No. Users), %f (Jacc)\" % (\n",
    "            eps, delta_recall[-1], delta_arp[-1], delta_poplift[-1], percentage_impacted_users[-1], average_jaccard_distance[-1]))\n",
    "    print()\n",
    "    return delta_recall, delta_arp, delta_poplift\n",
    "\n",
    "# wrapper for the evaluation, calculates all necessary resources, e.g., item popularity distribution, user profile popularity, ...\n",
    "def get_results(dataset_name, algos):\n",
    "    test_df = pd.read_csv(\"dataset/\" + dataset_name + \"/\" + dataset_name + \".test.inter\", sep=\"\\t\")\n",
    "    test_df.rename(columns={\"user_id:token\": \"user_id\", \"item_id:token\": \"item_id\"}, inplace=True)\n",
    "    test_df[\"user_id\"] = test_df[\"user_id\"].astype(str)\n",
    "    test_df[\"item_id\"] = test_df[\"item_id\"].astype(str)\n",
    "    groundtruth = test_df.groupby(\"user_id\")[\"item_id\"].apply(set)\n",
    "\n",
    "    df = pd.read_csv(\"dataset/\" + dataset_name + \"/\" + dataset_name + \".inter\", sep=\"\\t\")\n",
    "    df.rename(columns={\"user_id:token\": \"user_id\", \"item_id:token\": \"item_id\"}, inplace=True)\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"item_id\"] = df[\"item_id\"].astype(str)\n",
    "    item_popularity = df.groupby(\"item_id\").size() / df[\"user_id\"].nunique()\n",
    "\n",
    "    user_profile_pop = df.groupby(\"user_id\")[\"item_id\"].apply(list).apply(lambda iids: np.mean([item_popularity.loc[iid] for iid in iids]))\n",
    "\n",
    "    recall, arp, poplift = dict(), dict(), dict()\n",
    "    for algo in algos:\n",
    "        recall_a, arp_a, poplift_a = analyze(dataset_name=dataset_name, model_name=algo, groundtruth=groundtruth, user_profile_popularity=user_profile_pop, item_popularity=item_popularity)\n",
    "        recall[algo] = recall_a\n",
    "        arp[algo] = arp_a\n",
    "        poplift[algo] = poplift_a\n",
    "\n",
    "    return recall, arp, poplift"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the evaluation (RQ1, RQ2, RQ3a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recall_ml1m, arp_ml1m, poplift_ml1m = get_results(dataset_name=\"ml-1m\", algos=[\"ENMF\", \"LightGCN\", \"MultiVAE\"])\n",
    "recall_lfm, arp_lfm, poplift_lfm = get_results(dataset_name=\"LFM-3k\", algos=[\"ENMF\", \"LightGCN\", \"MultiVAE\"])\n",
    "recall_amazon, arp_amazon, poplift_amazon = get_results(dataset_name=\"grocery\", algos=[\"ENMF\", \"LightGCN\", \"MultiVAE\"])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the delta recall, delta arp, delta poplift values for epsilon=0.1\n",
    "\n",
    "print([(model, recalls[-2])for model, recalls in recall_ml1m.items()])\n",
    "print([(model, recalls[-2])for model, recalls in recall_lfm.items()])\n",
    "print([(model, recalls[-2])for model, recalls in recall_amazon.items()])\n",
    "\n",
    "print([(model, arps[-2])for model, arps in arp_ml1m.items()])\n",
    "print([(model, arps[-2])for model, arps in arp_lfm.items()])\n",
    "print([(model, arps[-2])for model, arps in arp_amazon.items()])\n",
    "\n",
    "print([(model, poplifts[-2])for model, poplifts in poplift_ml1m.items()])\n",
    "print([(model, poplifts[-2])for model, poplifts in poplift_lfm.items()])\n",
    "print([(model, poplifts[-2])for model, poplifts in poplift_amazon.items()])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Delta Recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_eps = [0.01, 0.1, 1, 2, 3, 4, 5]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax1 = plt.subplot2grid(shape=(1,3), loc=(0,0), fig=fig)\n",
    "ax2 = plt.subplot2grid((1,3), (0,1))\n",
    "ax3 = plt.subplot2grid((1,3), (0,2))\n",
    "\n",
    "ax1.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "ax2.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "ax3.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "\n",
    "ax1.plot(all_eps, recall_ml1m[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax1.plot(all_eps, recall_ml1m[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax1.plot(all_eps, recall_ml1m[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax1.invert_xaxis()\n",
    "\n",
    "ax2.plot(all_eps, recall_lfm[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax2.plot(all_eps, recall_lfm[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax2.plot(all_eps, recall_lfm[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "ax3.plot(all_eps, recall_amazon[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax3.plot(all_eps, recall_amazon[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax3.plot(all_eps, recall_amazon[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax3.invert_xaxis()\n",
    "\n",
    "ax1.set_ylabel(r\"$\\Delta Recall$ in \\%\", fontsize=\"large\")\n",
    "ax1.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "ax2.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "ax3.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "\n",
    "ax1.set_title(r\"\\emph{MovieLens 1M}\")\n",
    "ax2.set_title(r\"\\emph{LastFM User Groups}\")\n",
    "ax3.set_title(r\"\\emph{Amazon Grocery \\& Gourmet}\")\n",
    "\n",
    "ax1.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax2.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax3.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax2.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax3.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "lines = []\n",
    "lines.append(Line2D([0], [0], color=\"C0\", linestyle=\"dotted\"))\n",
    "lines.append(Line2D([0], [0], color=\"C1\", linestyle=\"dashed\"))\n",
    "lines.append(Line2D([0], [0], color=\"C2\", linestyle=\"dashdot\"))\n",
    "labels = [\"ENMF\", \"LightGCN\", \"MultVAE\"]\n",
    "\n",
    "fig.legend(lines, labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, .99), fontsize=\"large\")\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.8, bottom=0.15, wspace=0.25)\n",
    "fig.align_ylabels([ax1, ax2, ax3])\n",
    "\n",
    "#plt.savefig(\"plots/delta_recall.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Delta ARP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_eps = [0.01, 0.1, 1, 2, 3, 4, 5]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax1 = plt.subplot2grid(shape=(1,3), loc=(0,0), fig=fig)\n",
    "ax2 = plt.subplot2grid((1,3), (0,1))\n",
    "ax3 = plt.subplot2grid((1,3), (0,2))\n",
    "\n",
    "ax1.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "ax2.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "ax3.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "\n",
    "ax1.plot(all_eps, arp_ml1m[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax1.plot(all_eps, arp_ml1m[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax1.plot(all_eps, arp_ml1m[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax1.invert_xaxis()\n",
    "\n",
    "ax2.plot(all_eps, arp_lfm[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax2.plot(all_eps, arp_lfm[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax2.plot(all_eps, arp_lfm[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "ax3.plot(all_eps, arp_amazon[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax3.plot(all_eps, arp_amazon[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax3.plot(all_eps, arp_amazon[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax3.invert_xaxis()\n",
    "\n",
    "ax1.set_ylabel(r\"$\\Delta ARP$ in \\%\", fontsize=\"large\")\n",
    "ax1.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "ax2.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "ax3.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "\n",
    "ax1.set_title(r\"\\emph{MovieLens 1M}\")\n",
    "ax2.set_title(r\"\\emph{LastFM User Groups}\")\n",
    "ax3.set_title(r\"\\emph{Amazon Grocery \\& Gourmet}\")\n",
    "\n",
    "ax1.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax2.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax3.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax2.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax3.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "lines = []\n",
    "lines.append(Line2D([0], [0], color=\"C0\", linestyle=\"dotted\"))\n",
    "lines.append(Line2D([0], [0], color=\"C1\", linestyle=\"dashed\"))\n",
    "lines.append(Line2D([0], [0], color=\"C2\", linestyle=\"dashdot\"))\n",
    "labels = [\"ENMF\", \"LightGCN\", \"MultVAE\"]\n",
    "\n",
    "fig.legend(lines, labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, .99), fontsize=\"large\")\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.8, bottom=0.15, wspace=0.25)\n",
    "fig.align_ylabels([ax1, ax2, ax3])\n",
    "#plt.savefig(\"plots/delta_arp.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Delta PopLift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_eps = [0.01, 0.1, 1, 2, 3, 4, 5]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax1 = plt.subplot2grid(shape=(1,3), loc=(0,0), fig=fig)\n",
    "ax2 = plt.subplot2grid((1,3), (0,1))\n",
    "ax3 = plt.subplot2grid((1,3), (0,2))\n",
    "\n",
    "ax1.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "ax2.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "ax3.axhline(y=0, linestyle=\"dashed\", c=\"gray\")\n",
    "\n",
    "ax1.plot(all_eps, poplift_ml1m[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax1.plot(all_eps, poplift_ml1m[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax1.plot(all_eps, poplift_ml1m[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax1.invert_xaxis()\n",
    "\n",
    "ax2.plot(all_eps, poplift_lfm[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax2.plot(all_eps, poplift_lfm[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax2.plot(all_eps, poplift_lfm[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "ax3.plot(all_eps, poplift_amazon[\"ENMF\"][::-1], color=\"C0\", linewidth=3, linestyle=\"dotted\")\n",
    "ax3.plot(all_eps, poplift_amazon[\"LightGCN\"][::-1], color=\"C1\", linewidth=3, linestyle=\"dashed\")\n",
    "ax3.plot(all_eps, poplift_amazon[\"MultiVAE\"][::-1], color=\"C2\", linewidth=3, linestyle=\"dashdot\")\n",
    "ax3.invert_xaxis()\n",
    "\n",
    "ax1.set_ylabel(r\"$\\Delta PopLift$ in \\%\", fontsize=\"large\")\n",
    "ax1.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "ax2.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "ax3.set_xlabel(r\"Privacy Budget $\\epsilon$\", fontsize=\"large\")\n",
    "\n",
    "ax1.set_title(r\"\\emph{MovieLens 1M}\")\n",
    "ax2.set_title(r\"\\emph{LastFM User Groups}\")\n",
    "ax3.set_title(r\"\\emph{Amazon Grocery \\& Gourmet}\")\n",
    "\n",
    "ax1.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax2.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax3.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax2.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax3.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "lines = []\n",
    "lines.append(Line2D([0], [0], color=\"C0\", linestyle=\"dotted\"))\n",
    "lines.append(Line2D([0], [0], color=\"C1\", linestyle=\"dashed\"))\n",
    "lines.append(Line2D([0], [0], color=\"C2\", linestyle=\"dashdot\"))\n",
    "labels = [\"ENMF\", \"LightGCN\", \"MultVAE\"]\n",
    "\n",
    "fig.legend(lines, labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, .99), fontsize=\"large\")\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.8, bottom=0.15, wspace=0.25)\n",
    "fig.align_ylabels([ax1, ax2, ax3])\n",
    "#plt.savefig(\"plots/delta_pl.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate PopLift for two User Groups (RQ3b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate the absolute poplift values for U_low and U_high\n",
    "def analyze_poplift_usergroups(dataset_name, model_name):\n",
    "    def _compute_poplift(dirpath, item_popularity, user_profile_popularity, group):\n",
    "        files = sort_files(dirpath)\n",
    "        poplifts = []\n",
    "        for idx, file in enumerate(files):\n",
    "            with open(dirpath + \"/\" + file, \"rb\") as f:\n",
    "                recommendation_list = pl.load(f)\n",
    "                arp_g, upp_g = [], []\n",
    "                for uid, recs in recommendation_list.items():\n",
    "                    if uid not in group[idx]:\n",
    "                        continue\n",
    "\n",
    "                    arp_g.append(np.mean([item_popularity.loc[str(iid)] for iid in recs]))\n",
    "                    upp_g.append(user_profile_popularity.loc[uid])\n",
    "\n",
    "                poplifts.append((np.mean(arp_g) - np.mean(upp_g)) / np.mean(upp_g))\n",
    "        return np.mean(poplifts)\n",
    "\n",
    "    print()\n",
    "    print(model_name + \" (\" + dataset_name + \")\")\n",
    "\n",
    "    df = pd.read_csv(\"dataset/\" + dataset_name + \"/\" + dataset_name + \".inter\", sep=\"\\t\")\n",
    "    df.rename(columns={\"user_id:token\": \"user_id\", \"item_id:token\": \"item_id\"}, inplace=True)\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"item_id\"] = df[\"item_id\"].astype(str)\n",
    "    item_popularity = df.groupby(\"item_id\").size() / df[\"user_id\"].nunique()\n",
    "    user_profile_pop = df.groupby(\"user_id\")[\"item_id\"].apply(list).apply(lambda iids: np.mean([item_popularity.loc[iid] for iid in iids]))\n",
    "    cut = int(len(item_popularity) * 0.2)\n",
    "    head_items = set(item_popularity.sort_values(ascending=False).iloc[:cut].index.tolist())\n",
    "    frac_pop_items = df.groupby(\"user_id\")[\"item_id\"].apply(set).apply(lambda items: len(items.intersection(head_items)) / len(items))\n",
    "    frac_pop_items.name = \"frac\"\n",
    "    cut = int(len(frac_pop_items) * 0.2)\n",
    "    low_users = frac_pop_items.sort_values().head(cut).index.tolist()\n",
    "    high_users = frac_pop_items.sort_values().tail(cut).index.tolist()\n",
    "\n",
    "    dir = \"saved/\" + dataset_name + \"/\" + model_name + \"/\"\n",
    "\n",
    "    pl1_nodp = _compute_poplift(dirpath=dir + \"nodp\", item_popularity=item_popularity, user_profile_popularity=user_profile_pop, group=[low_users] * 5)\n",
    "    pl2_nodp = _compute_poplift(dirpath=dir + \"nodp\", item_popularity=item_popularity, user_profile_popularity=user_profile_pop, group=[high_users] * 5)\n",
    "    print(\"No DP: %.4f/%.4f (PopLift), %.4f\" % (pl1_nodp, pl2_nodp, np.abs(pl1_nodp - pl2_nodp)))\n",
    "\n",
    "    poplifts1, poplifts2 = [], []\n",
    "    for eps in [0.01, 0.1, 1, 2, 3, 4, 5][::-1]:\n",
    "        users, _, _ = _get_impacted_users(dirpath_nodp=dir + \"nodp\", dirpath_dp=dir + \"e\" + str(eps))\n",
    "        group1_and_impacted, group2_and_impacted = [], []\n",
    "        for users_s in users:\n",
    "            group1_and_impacted.append(set([uid for uid in users_s]).intersection(low_users))\n",
    "            group2_and_impacted.append(set([uid for uid in users_s]).intersection(high_users))\n",
    "\n",
    "        pl1_eps = _compute_poplift(dirpath=dir + \"e\" + str(eps), item_popularity=item_popularity, user_profile_popularity=user_profile_pop, group=group1_and_impacted)\n",
    "        pl2_eps = _compute_poplift(dirpath=dir + \"e\" + str(eps), item_popularity=item_popularity, user_profile_popularity=user_profile_pop, group=group2_and_impacted)\n",
    "\n",
    "        poplifts1.append(pl1_eps)\n",
    "        poplifts2.append(pl2_eps)\n",
    "\n",
    "        print(\"eps: %f -> %.4f/%.4f (PopLift), %.4f (Gap)\" % (eps, poplifts1[-1], poplifts2[-1], np.abs(poplifts1[-1] - poplifts2[-1])))\n",
    "\n",
    "    return poplifts1, poplifts2\n",
    "\n",
    "for d in [\"ml-1m\", \"LFM-3k\", \"grocery\"]:\n",
    "    for m in [\"ENMF\", \"LightGCN\", \"MultiVAE\"]:\n",
    "        analyze_poplift_usergroups(dataset_name=d, model_name=m)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
